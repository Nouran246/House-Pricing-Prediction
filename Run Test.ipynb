{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "import joblib\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from google.colab import drive\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
        "from sklearn.model_selection import learning_curve\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer"
      ],
      "metadata": {
        "id": "2CacfbYvTbgZ"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "5y-66Xk3S5H3"
      },
      "outputs": [],
      "source": [
        "def Data_Preparation(dataset_path):\n",
        "    # Load dataset\n",
        "    dataset = pd.read_csv(dataset_path)\n",
        "\n",
        "    # Drop unnecessary columns\n",
        "    if 'Id' in dataset.columns:\n",
        "        dataset.drop(['Id'], axis=1, inplace=True)\n",
        "\n",
        "    # Handle missing values in SalePrice (Mean Imputation)\n",
        "    dataset['SalePrice'] = dataset['SalePrice'].fillna(\n",
        "    dataset['SalePrice'].mean())\n",
        "\n",
        "    # Removing Missing Values from the Dataset\n",
        "    new_dataset = dataset.dropna()\n",
        "\n",
        "    # Missing Values Check\n",
        "    new_dataset.isnull().sum()\n",
        "\n",
        "    # List Categorical Features\n",
        "    from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "    s = (new_dataset.dtypes == 'object')\n",
        "    object_cols = list(s[s].index)\n",
        "    print(\"Categorical variables:\")\n",
        "    print(object_cols)\n",
        "    print('No. of. categorical features: ',\n",
        "\t  len(object_cols))\n",
        "\n",
        "    # Impute missing values in categorical columns with 'Missing'\n",
        "    for col in object_cols:\n",
        "      dataset[col] = dataset[col].fillna('Missing')\n",
        "\n",
        "    # Drop rows with missing values in numerical columns (if any)\n",
        "    new_dataset = dataset.dropna(subset=[col for col in dataset.columns if col not in object_cols])\n",
        "\n",
        "    # One-hot encoding\n",
        "    OH_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "    OH_cols = pd.DataFrame(OH_encoder.fit_transform(new_dataset[object_cols]))\n",
        "    OH_cols.index = new_dataset.index\n",
        "    OH_cols.columns = OH_encoder.get_feature_names_out()\n",
        "    df_final = new_dataset.drop(object_cols, axis=1)\n",
        "    df_final = pd.concat([df_final, OH_cols], axis=1)\n",
        "\n",
        "    # Standardization\n",
        "    scaler = StandardScaler()\n",
        "    numeric_features = df_final.select_dtypes(include=['number']).columns\n",
        "    df_final[numeric_features] = scaler.fit_transform(df_final[numeric_features])\n",
        "\n",
        "    # Define X (features) and y (target) before outlier handling\n",
        "    X = df_final.drop(columns=['SalePrice'])\n",
        "    y = df_final['SalePrice']\n",
        "\n",
        "\n",
        "    # Handle outliers using IQR method\n",
        "\n",
        "    Q1, Q3 = y.quantile(0.25), y.quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound, upper_bound = Q1 - 1.5 * IQR, Q3 + 1.5 * IQR\n",
        "    outlier_mask = (y >= lower_bound) & (y <= upper_bound)\n",
        "\n",
        "    # Update X and y using the outlier mask\n",
        "    X = X[outlier_mask]\n",
        "    y = y[outlier_mask]\n",
        "\n",
        "    # Apply log transformation\n",
        "    y = np.log1p(y)\n",
        "\n",
        "    #The X, y are already defined before outlier handling\n",
        "    y.dropna(inplace=True)\n",
        "    X = X.loc[y.index]\n",
        "\n",
        "    # Select 10 best features\n",
        "    selector = SelectKBest(score_func=mutual_info_regression, k=10)\n",
        "    X_selected = selector.fit_transform(X, y)\n",
        "\n",
        "    selected_features = X.columns[selector.get_support()]\n",
        "    print(\"Top 10 Important Features:\\n\", selected_features.tolist())\n",
        "\n",
        "    df_final = df_final[selected_features.tolist() + ['SalePrice']]\n",
        "\n",
        "\n",
        "\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "dataset_path = \"/content/drive/MyDrive/train.csv\"\n",
        "X, y = Data_Preparation(dataset_path)\n",
        "\n",
        "# Load trained model outside the function\n",
        "model_path = \"/content/drive/My Drive/lasso_model.pkl\"\n",
        "model = joblib.load(model_path)\n",
        "print(\"Model loaded successfully!\")\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(X)\n",
        "\n",
        "# Print evaluation metrics if y is available\n",
        "if y is not None:\n",
        "    from sklearn.metrics import mean_absolute_percentage_error, r2_score\n",
        "    print(f\"MAPE: {mean_absolute_percentage_error(y, predictions):.4f}\")\n",
        "    print(f\"R² Score: {r2_score(y, predictions):.4f}\")\n",
        "\n",
        "print(\"Predictions:\", predictions[:5])  # Print first 5 predictions"
      ],
      "metadata": {
        "id": "rI50H-6lTALV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bbb8223-a555-449a-8fad-1f367fdea354"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Categorical variables:\n",
            "['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', 'SaleType', 'SaleCondition']\n",
            "No. of. categorical features:  43\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 Important Features:\n",
            " ['OverallQual', 'YearBuilt', 'TotalBsmtSF', 'GrLivArea', 'FullBath', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'ExterQual_Gd', 'ExterQual_TA']\n",
            "Model loaded successfully!\n",
            "MAPE: 2.1415\n",
            "R² Score: 0.0398\n",
            "Predictions: [-0.06855849 -0.13861112 -0.06855849 -0.06855849  0.00149413]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but Lasso was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}